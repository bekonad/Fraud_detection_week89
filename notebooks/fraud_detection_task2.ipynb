{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "v11vu9d8GWgt",
        "outputId": "9ff06afd-7fa4-4f5b-98b4-6f0cba4e579c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'null' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3785365495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   {\n\u001b[1;32m     19\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m    \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m    \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
          ]
        }
      ],
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# Fraud Detection Task 1 - Data Preprocessing and EDA\\n\",\n",
        "    \"\\n\",\n",
        "    \"## Overview\\n\",\n",
        "    \"This notebook handles the preprocessing of raw datasets (`Fraud_Data.csv`, `creditcard.csv`, `IpAddress_to_Country.csv`), performs exploratory data analysis (EDA), and engineers features. Part of my 10 Academy KAIM Week 8 & 9 Challenge submission. Last updated: 02:45 AM EAT, Tuesday, August 26, 2025.
        "    \"\\n\",\n",
        "    \"## Objectives\\n\",\n",
        "    \"- Load and clean raw datasets.\\n\",\n",
        "    \"- Map IP addresses to countries.\\n\",\n",
        "    \"- Perform EDA and visualize data.\\n\",\n",
        "    \"- Apply SMOTE for class imbalance.\\n\",\n",
        "    \"- Save processed datasets.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Install required packages\\n\",\n",
        "    \"!pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn joblib\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Import libraries\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"import numpy as np\\n\",\n",
        "    \"import matplotlib.pyplot as plt\\n\",\n",
        "    \"import seaborn as sns\\n\",\n",
        "    \"from imblearn.over_sampling import SMOTE\\n\",\n",
        "    \"import logging\\n\",\n",
        "    \"import os\\n\",\n",
        "    \"from sklearn.model_selection import train_test_split\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Configure logging\\n\",\n",
        "    \"logging.basicConfig(level=logging.INFO, filename='/content/drive/MyDrive/outputs/task1_output.log', format='%(asctime)s - %(levelname)s - %(message)s')\\n\",\n",
        "    \"logger = logging.getLogger(__name__)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Mount Google Drive\\n\",\n",
        "    \"from google.colab import drive\\n\",\n",
        "    \"drive.mount('/content/drive')\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Create necessary folders\\n\",\n",
        "    \"folders = [\\n\",\n",
        "    \"    '/content/drive/MyDrive/Data/raw',\\n\",\n",
        "    \"    '/content/drive/MyDrive/Data/processed',\\n\",\n",
        "    \"    '/content/drive/MyDrive/reports/eda',\\n\",\n",
        "    \"    '/content/drive/MyDrive/reports/models',\\n\",\n",
        "    \"    '/content/drive/MyDrive/reports/confusion_matrices',\\n\",\n",
        "    \"    '/content/drive/MyDrive/outputs'\\n\",\n",
        "    \"]\\n\",\n",
        "    \"for folder in folders:\\n\",\n",
        "    \"    os.makedirs(folder, exist_ok=True)\\n\",\n",
        "    \"    logger.info(f\\\"Created folder: {folder}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Verify folder creation\\n\",\n",
        "    \"!ls /content/drive/MyDrive/Data\\n\",\n",
        "    \"!ls /content/drive/MyDrive/reports\\n\",\n",
        "    \"!ls /content/drive/MyDrive/outputs\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Data Loading and Preprocessing\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Load datasets\\n\",\n",
        "    \"fraud_data = pd.read_csv('/content/drive/MyDrive/Data/raw/Fraud_Data.csv')\\n\",\n",
        "    \"creditcard_data = pd.read_csv('/content/drive/MyDrive/Data/raw/creditcard.csv')\\n\",\n",
        "    \"ip_to_country = pd.read_csv('/content/drive/MyDrive/Data/raw/IpAddress_to_Country.csv')\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Clean data (remove duplicates, handle missing values)\\n\",\n",
        "    \"fraud_data = fraud_data.drop_duplicates().dropna()\\n\",\n",
        "    \"creditcard_data = creditcard_data.drop_duplicates().dropna()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Map IP addresses to countries (placeholder logic)\\n\",\n",
        "    \"def map_ip_to_country(ip, ip_to_country_df):\\n\",\n",
        "    \"    # Implement logic to map IP to country (e.g., binary search or range matching)\\n\",\n",
        "    \"    return ip_to_country_df[ip_to_country_df['ip_start'] <= int(ip)].iloc[-1]['country'] if not ip_to_country_df.empty else 'Unknown'\\n\",\n",
        "    \"\\n\",\n",
        "    \"fraud_data['ip_address'] = fraud_data['ip_address'].astype(float).astype(int)  # Convert IP to integer for mapping\\n\",\n",
        "    \"fraud_data['country'] = fraud_data['ip_address'].apply(lambda x: map_ip_to_country(x, ip_to_country))\\n\",\n",
        "    \"logger.info(\\\"IP addresses mapped to countries.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Feature engineering (e.g., time_to_purchase)\\n\",\n",
        "    \"fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\\n\",\n",
        "    \"fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\\n\",\n",
        "    \"fraud_data['time_to_purchase'] = (fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds() / 3600  # Hours\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Select features and target\\n\",\n",
        "    \"features = ['time_to_purchase', 'purchase_value', 'country']  # Adjust based on your dataset\\n\",\n",
        "    \"X = fraud_data[features]\\n\",\n",
        "    \"y = fraud_data['is_fraud']\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Exploratory Data Analysis (EDA)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Visualize class distribution\\n\",\n",
        "    \"plt.figure(figsize=(8, 6))\\n\",\n",
        "    \"sns.countplot(x='is_fraud', data=fraud_data)\\n\",\n",
        "    \"plt.title('Class Distribution')\\n\",\n",
        "    \"plt.savefig('/content/drive/MyDrive/reports/eda/class_distribution.png')\\n\",\n",
        "    \"plt.close()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Visualize purchase patterns\\n\",\n",
        "    \"plt.figure(figsize=(8, 6))\\n\",\n",
        "    \"sns.histplot(data=fraud_data, x='purchase_value', hue='is_fraud', kde=True)\\n\",\n",
        "    \"plt.title('Purchase Value Distribution by Fraud Status')\\n\",\n",
        "    \"plt.savefig('/content/drive/MyDrive/reports/eda/purchase_patterns.png')\\n\",\n",
        "    \"plt.close()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Bivariate analysis (boxplots)\\n\",\n",
        "    \"plt.figure(figsize=(10, 6))\\n\",\n",
        "    \"sns.boxplot(x='is_fraud', y='purchase_value', data=fraud_data)\\n\",\n",
        "    \"plt.title('Purchase Value vs Fraud Status')\\n\",\n",
        "    \"plt.savefig('/content/drive/MyDrive/reports/eda/bivariate_boxplots.png')\\n\",\n",
        "    \"plt.close()\\n\",\n",
        "    \"logger.info(\\\"EDA visualizations saved.\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Handle Class Imbalance with SMOTE\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Apply SMOTE\\n\",\n",
        "    \"smote = SMOTE(random_state=42)\\n\",\n",
        "    \"X_resampled, y_resampled = smote.fit_resample(X, y)\\n\",\n",
        "    \"logger.info(\\\"SMOTE applied for class imbalance.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Split into train and test sets\\n\",\n",
        "    \"X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Save processed data\\n\",\n",
        "    \"train_data = pd.concat([X_train, y_train], axis=1)\\n\",\n",
        "    \"test_data = pd.concat([X_test, y_test], axis=1)\\n\",\n",
        "    \"train_data.to_csv('/content/drive/MyDrive/Data/processed/fraud_train_processed.csv', index=False)\\n\",\n",
        "    \"test_data.to_csv('/content/drive/MyDrive/Data/processed/fraud_test_processed.csv', index=False)\\n\",\n",
        "    \"y_train.to_csv('/content/drive/MyDrive/Data/processed/y_fraud_train.csv', index=False)\\n\",\n",
        "    \"y_test.to_csv('/content/drive/MyDrive/Data/processed/y_fraud_test.csv', index=False)\\n\",\n",
        "    \"logger.info(\\\"Processed datasets saved to Data/processed/.\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Conclusion\\n\",\n",
        "    \"Data preprocessing, EDA, and feature engineering are complete. Logs are saved to `outputs/task1_output.log`.\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.10\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# Fraud Detection Task 1 - Data Preprocessing and EDA\\n\",\n",
        "    \"\\n\",\n",
        "    \"## Overview\\n\",\n",
        "    \"This notebook handles the preprocessing of raw datasets (`Fraud_Data.csv`, `creditcard.csv`, `IpAddress_to_Country.csv`), performs exploratory data analysis (EDA), and engineers features. Part of my 10 Academy KAIM Week 8 & 9 Challenge submission. Last updated: 02:45 AM EAT, Tuesday, August 26, 2025.
        "    \"\\n\",\n",
        "    \"## Objectives\\n\",\n",
        "    \"- Load and clean raw datasets.\\n\",\n",
        "    \"- Map IP addresses to countries.\\n\",\n",
        "    \"- Perform EDA and visualize data.\\n\",\n",
        "    \"- Apply SMOTE for class imbalance.\\n\",\n",
        "    \"- Save processed datasets.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 1,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Install required packages\\n\",\n",
        "    \"!pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn joblib\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Import libraries\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"import numpy as np\\n\",\n",
        "    \"import matplotlib.pyplot as plt\\n\",\n",
        "    \"import seaborn as sns\\n\",\n",
        "    \"from imblearn.over_sampling import SMOTE\\n\",\n",
        "    \"import logging\\n\",\n",
        "    \"import os\\n\",\n",
        "    \"from sklearn.model_selection import train_test_split\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Configure logging\\n\",\n",
        "    \"logging.basicConfig(level=logging.INFO, filename='/content/drive/MyDrive/outputs/task1_output.log', format='%(asctime)s - %(levelname)s - %(message)s')\\n\",\n",
        "    \"logger = logging.getLogger(__name__)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Mount Google Drive\\n\",\n",
        "    \"from google.colab import drive\\n\",\n",
        "    \"drive.mount('/content/drive')\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Create necessary folders\\n\",\n",
        "    \"folders = [\\n\",\n",
        "    \"    '/content/drive/MyDrive/Data/raw',\\n\",\n",
        "    \"    '/content/drive/MyDrive/Data/processed',\\n\",\n",
        "    \"    '/content/drive/MyDrive/reports/eda',\\n\",\n",
        "    \"    '/content/drive/MyDrive/reports/models',\\n\",\n",
        "    \"    '/content/drive/MyDrive/reports/confusion_matrices',\\n\",\n",
        "    \"    '/content/drive/MyDrive/outputs'\\n\",\n",
        "    \"]\\n\",\n",
        "    \"for folder in folders:\\n\",\n",
        "    \"    os.makedirs(folder, exist_ok=True)\\n\",\n",
        "    \"    logger.info(f\\\"Created folder: {folder}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Verify folder creation\\n\",\n",
        "    \"!ls /content/drive/MyDrive/Data\\n\",\n",
        "    \"!ls /content/drive/MyDrive/reports\\n\",\n",
        "    \"!ls /content/drive/MyDrive/outputs\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Data Loading and Preprocessing\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 1,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Load datasets\\n\",\n",
        "    \"fraud_data = pd.read_csv('/content/drive/MyDrive/Data/raw/Fraud_Data.csv')\\n\",\n",
        "    \"creditcard_data = pd.read_csv('/content/drive/MyDrive/Data/raw/creditcard.csv')\\n\",\n",
        "    \"ip_to_country = pd.read_csv('/content/drive/MyDrive/Data/raw/IpAddress_to_Country.csv')\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Clean data (remove duplicates, handle missing values)\\n\",\n",
        "    \"fraud_data = fraud_data.drop_duplicates().dropna()\\n\",\n",
        "    \"creditcard_data = creditcard_data.drop_duplicates().dropna()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Map IP addresses to countries (placeholder logic)\\n\",\n",
        "    \"def map_ip_to_country(ip, ip_to_country_df):\\n\",\n",
        "    \"    # Implement logic to map IP to country (e.g., binary search or range matching)\\n\",\n",
        "    \"    return ip_to_country_df[ip_to_country_df['ip_start'] <= int(ip)].iloc[-1]['country'] if not ip_to_country_df.empty else 'Unknown'\\n\",\n",
        "    \"\\n\",\n",
        "    \"fraud_data['ip_address'] = fraud_data['ip_address'].astype(float).astype(int)  # Convert IP to integer for mapping\\n\",\n",
        "    \"fraud_data['country'] = fraud_data['ip_address'].apply(lambda x: map_ip_to_country(x, ip_to_country))\\n\",\n",
        "    \"logger.info(\\\"IP addresses mapped to countries.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Feature engineering (e.g., time_to_purchase)\\n\",\n",
        "    \"fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\\n\",\n",
        "    \"fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\\n\",\n",
        "    \"fraud_data['time_to_purchase'] = (fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds() / 3600  # Hours\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Select features and target\\n\",\n",
        "    \"features = ['time_to_purchase', 'purchase_value', 'country']  # Adjust based on your dataset\\n\",\n",
        "    \"X = fraud_data[features]\\n\",\n",
        "    \"y = fraud_data['is_fraud']\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Exploratory Data Analysis (EDA)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 1,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Visualize class distribution\\n\",\n",
        "    \"plt.figure(figsize=(8, 6))\\n\",\n",
        "    \"sns.countplot(x='is_fraud', data=fraud_data)\\n\",\n",
        "    \"plt.title('Class Distribution')\\n\",\n",
        "    \"plt.savefig('/content/drive/MyDrive/reports/eda/class_distribution.png')\\n\",\n",
        "    \"plt.close()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Visualize purchase patterns\\n\",\n",
        "    \"plt.figure(figsize=(8, 6))\\n\",\n",
        "    \"sns.histplot(data=fraud_data, x='purchase_value', hue='is_fraud', kde=True)\\n\",\n",
        "    \"plt.title('Purchase Value Distribution by Fraud Status')\\n\",\n",
        "    \"plt.savefig('/content/drive/MyDrive/reports/eda/purchase_patterns.png')\\n\",\n",
        "    \"plt.close()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Bivariate analysis (boxplots)\\n\",\n",
        "    \"plt.figure(figsize=(10, 6))\\n\",\n",
        "    \"sns.boxplot(x='is_fraud', y='purchase_value', data=fraud_data)\\n\",\n",
        "    \"plt.title('Purchase Value vs Fraud Status')\\n\",\n",
        "    \"plt.savefig('/content/drive/MyDrive/reports/eda/bivariate_boxplots.png')\\n\",\n",
        "    \"plt.close()\\n\",\n",
        "    \"logger.info(\\\"EDA visualizations saved.\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Handle Class Imbalance with SMOTE\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 1,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Apply SMOTE\\n\",\n",
        "    \"smote = SMOTE(random_state=42)\\n\",\n",
        "    \"X_resampled, y_resampled = smote.fit_resample(X, y)\\n\",\n",
        "    \"logger.info(\\\"SMOTE applied for class imbalance.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Split into train and test sets\\n\",\n",
        "    \"X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Save processed data\\n\",\n",
        "    \"train_data = pd.concat([X_train, y_train], axis=1)\\n\",\n",
        "    \"test_data = pd.concat([X_test, y_test], axis=1)\\n\",\n",
        "    \"train_data.to_csv('/content/drive/MyDrive/Data/processed/fraud_train_processed.csv', index=False)\\n\",\n",
        "    \"test_data.to_csv('/content/drive/MyDrive/Data/processed/fraud_test_processed.csv', index=False)\\n\",\n",
        "    \"y_train.to_csv('/content/drive/MyDrive/Data/processed/y_fraud_train.csv', index=False)\\n\",\n",
        "    \"y_test.to_csv('/content/drive/MyDrive/Data/processed/y_fraud_test.csv', index=False)\\n\",\n",
        "    \"logger.info(\\\"Processed datasets saved to Data/processed/.\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Conclusion\\n\",\n",
        "    \"Data preprocessing, EDA, and feature engineering are complete. Logs are saved to `outputs/task1_output.log`.\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.10\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 0\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjtKfcvbHOv-",
        "outputId": "ff0fb5b8-7362-4249-b49f-9ea276bcbeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cells': [{'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['# Fraud Detection Task 1 - Data Preprocessing and EDA\\n',\n",
              "    '\\n',\n",
              "    '## Overview\\n',\n",
              "    'This notebook handles the preprocessing of raw datasets (`Fraud_Data.csv`, `creditcard.csv`, `IpAddress_to_Country.csv`), performs exploratory data analysis (EDA), and engineers features. Part of my 10 Academy KAIM Week 8 & 9 Challenge submission. Last updated: 02:45 AM EAT, Tuesday, August 26, 2025.
              "    '\\n',\n",
              "    '## Objectives\\n',\n",
              "    '- Load and clean raw datasets.\\n',\n",
              "    '- Map IP addresses to countries.\\n',\n",
              "    '- Perform EDA and visualize data.\\n',\n",
              "    '- Apply SMOTE for class imbalance.\\n',\n",
              "    '- Save processed datasets.']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 1,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['# Install required packages\\n',\n",
              "    '!pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn joblib\\n',\n",
              "    '\\n',\n",
              "    '# Import libraries\\n',\n",
              "    'import pandas as pd\\n',\n",
              "    'import numpy as np\\n',\n",
              "    'import matplotlib.pyplot as plt\\n',\n",
              "    'import seaborn as sns\\n',\n",
              "    'from imblearn.over_sampling import SMOTE\\n',\n",
              "    'import logging\\n',\n",
              "    'import os\\n',\n",
              "    'from sklearn.model_selection import train_test_split\\n',\n",
              "    '\\n',\n",
              "    '# Configure logging\\n',\n",
              "    \"logging.basicConfig(level=logging.INFO, filename='/content/drive/MyDrive/outputs/task1_output.log', format='%(asctime)s - %(levelname)s - %(message)s')\\n\",\n",
              "    'logger = logging.getLogger(__name__)\\n',\n",
              "    '\\n',\n",
              "    '# Mount Google Drive\\n',\n",
              "    'from google.colab import drive\\n',\n",
              "    \"drive.mount('/content/drive')\\n\",\n",
              "    '\\n',\n",
              "    '# Create necessary folders\\n',\n",
              "    'folders = [\\n',\n",
              "    \"    '/content/drive/MyDrive/Data/raw',\\n\",\n",
              "    \"    '/content/drive/MyDrive/Data/processed',\\n\",\n",
              "    \"    '/content/drive/MyDrive/reports/eda',\\n\",\n",
              "    \"    '/content/drive/MyDrive/reports/models',\\n\",\n",
              "    \"    '/content/drive/MyDrive/reports/confusion_matrices',\\n\",\n",
              "    \"    '/content/drive/MyDrive/outputs'\\n\",\n",
              "    ']\\n',\n",
              "    'for folder in folders:\\n',\n",
              "    '    os.makedirs(folder, exist_ok=True)\\n',\n",
              "    '    logger.info(f\"Created folder: {folder}\")\\n',\n",
              "    '\\n',\n",
              "    '# Verify folder creation\\n',\n",
              "    '!ls /content/drive/MyDrive/Data\\n',\n",
              "    '!ls /content/drive/MyDrive/reports\\n',\n",
              "    '!ls /content/drive/MyDrive/outputs']},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## Data Loading and Preprocessing']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 1,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['# Load datasets\\n',\n",
              "    \"fraud_data = pd.read_csv('/content/drive/MyDrive/Data/raw/Fraud_Data.csv')\\n\",\n",
              "    \"creditcard_data = pd.read_csv('/content/drive/MyDrive/Data/raw/creditcard.csv')\\n\",\n",
              "    \"ip_to_country = pd.read_csv('/content/drive/MyDrive/Data/raw/IpAddress_to_Country.csv')\\n\",\n",
              "    '\\n',\n",
              "    '# Clean data (remove duplicates, handle missing values)\\n',\n",
              "    'fraud_data = fraud_data.drop_duplicates().dropna()\\n',\n",
              "    'creditcard_data = creditcard_data.drop_duplicates().dropna()\\n',\n",
              "    '\\n',\n",
              "    '# Map IP addresses to countries (placeholder logic)\\n',\n",
              "    'def map_ip_to_country(ip, ip_to_country_df):\\n',\n",
              "    '    # Implement logic to map IP to country (e.g., binary search or range matching)\\n',\n",
              "    \"    return ip_to_country_df[ip_to_country_df['ip_start'] <= int(ip)].iloc[-1]['country'] if not ip_to_country_df.empty else 'Unknown'\\n\",\n",
              "    '\\n',\n",
              "    \"fraud_data['ip_address'] = fraud_data['ip_address'].astype(float).astype(int)  # Convert IP to integer for mapping\\n\",\n",
              "    \"fraud_data['country'] = fraud_data['ip_address'].apply(lambda x: map_ip_to_country(x, ip_to_country))\\n\",\n",
              "    'logger.info(\"IP addresses mapped to countries.\")\\n',\n",
              "    '\\n',\n",
              "    '# Feature engineering (e.g., time_to_purchase)\\n',\n",
              "    \"fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\\n\",\n",
              "    \"fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\\n\",\n",
              "    \"fraud_data['time_to_purchase'] = (fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds() / 3600  # Hours\\n\",\n",
              "    '\\n',\n",
              "    '# Select features and target\\n',\n",
              "    \"features = ['time_to_purchase', 'purchase_value', 'country']  # Adjust based on your dataset\\n\",\n",
              "    'X = fraud_data[features]\\n',\n",
              "    \"y = fraud_data['is_fraud']\"]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## Exploratory Data Analysis (EDA)']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 1,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['# Visualize class distribution\\n',\n",
              "    'plt.figure(figsize=(8, 6))\\n',\n",
              "    \"sns.countplot(x='is_fraud', data=fraud_data)\\n\",\n",
              "    \"plt.title('Class Distribution')\\n\",\n",
              "    \"plt.savefig('/content/drive/MyDrive/reports/eda/class_distribution.png')\\n\",\n",
              "    'plt.close()\\n',\n",
              "    '\\n',\n",
              "    '# Visualize purchase patterns\\n',\n",
              "    'plt.figure(figsize=(8, 6))\\n',\n",
              "    \"sns.histplot(data=fraud_data, x='purchase_value', hue='is_fraud', kde=True)\\n\",\n",
              "    \"plt.title('Purchase Value Distribution by Fraud Status')\\n\",\n",
              "    \"plt.savefig('/content/drive/MyDrive/reports/eda/purchase_patterns.png')\\n\",\n",
              "    'plt.close()\\n',\n",
              "    '\\n',\n",
              "    '# Bivariate analysis (boxplots)\\n',\n",
              "    'plt.figure(figsize=(10, 6))\\n',\n",
              "    \"sns.boxplot(x='is_fraud', y='purchase_value', data=fraud_data)\\n\",\n",
              "    \"plt.title('Purchase Value vs Fraud Status')\\n\",\n",
              "    \"plt.savefig('/content/drive/MyDrive/reports/eda/bivariate_boxplots.png')\\n\",\n",
              "    'plt.close()\\n',\n",
              "    'logger.info(\"EDA visualizations saved.\")']},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## Handle Class Imbalance with SMOTE']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 1,\n",
              "   'metadata': {},\n",
              "   'outputs': [],\n",
              "   'source': ['# Apply SMOTE\\n',\n",
              "    'smote = SMOTE(random_state=42)\\n',\n",
              "    'X_resampled, y_resampled = smote.fit_resample(X, y)\\n',\n",
              "    'logger.info(\"SMOTE applied for class imbalance.\")\\n',\n",
              "    '\\n',\n",
              "    '# Split into train and test sets\\n',\n",
              "    'X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\\n',\n",
              "    '\\n',\n",
              "    '# Save processed data\\n',\n",
              "    'train_data = pd.concat([X_train, y_train], axis=1)\\n',\n",
              "    'test_data = pd.concat([X_test, y_test], axis=1)\\n',\n",
              "    \"train_data.to_csv('/content/drive/MyDrive/Data/processed/fraud_train_processed.csv', index=False)\\n\",\n",
              "    \"test_data.to_csv('/content/drive/MyDrive/Data/processed/fraud_test_processed.csv', index=False)\\n\",\n",
              "    \"y_train.to_csv('/content/drive/MyDrive/Data/processed/y_fraud_train.csv', index=False)\\n\",\n",
              "    \"y_test.to_csv('/content/drive/MyDrive/Data/processed/y_fraud_test.csv', index=False)\\n\",\n",
              "    'logger.info(\"Processed datasets saved to Data/processed/.\")']},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## Conclusion\\n',\n",
              "    'Data preprocessing, EDA, and feature engineering are complete. Logs are saved to `outputs/task1_output.log`.']}],\n",
              " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
              "   'language': 'python',\n",
              "   'name': 'python3'},\n",
              "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
              "   'file_extension': '.py',\n",
              "   'mimetype': 'text/x-python',\n",
              "   'name': 'python',\n",
              "   'nbconvert_exporter': 'python',\n",
              "   'pygments_lexer': 'ipython3',\n",
              "   'version': '3.10'}},\n",
              " 'nbformat': 4,\n",
              " 'nbformat_minor': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}